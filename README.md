# Prompt-Engineering-

Working with LLM's -- Large Language Models 

What are LLMs ? 
* LLMs are just an aspect of different AI models that enable them to communicate in human text and make them seem like they possess human intelect, but they work with a vast amount of data that enable them know different text, grammer, speeches and also a sophisticated engine that enable them predict the words that come next at every point in time.
An LLM is a model that uses Generative AI techniques, which are based on Deep Learning and Machine Learning, all of which fall under the umbrella of Artificial Intelligence. We can call them different techniques, ie Machine learning, deep learning, generative AI and LLMs.
  
What is a prompt ?
* Instructions and context provided to an AI for certain tasks

Prompt Engineering ? 
* the practice of developing and optimizing prompts to efficiently use an AI for a certain task

* Note that the only time these LLMs "think" is when they type
* You always want to bias the model towards being more accurate and  effective by asking it for evidence. You could also provide hints to guide the model in it's explanations 

 Some of the features of multi-modality include;
 * Acceptance and generation of text
 * Accept and generate images
 * Browse the internate particularly for information that's past it's cut of date
 * It can execute python code

AI models and their chatbots are 2 very different things. For instance, open AI model, OpenAI(GPT -4) would allow you interact with this model through chatgpt or the PaLM model by google through Bard or Gemini etc

In reality LLMs use Tokens to identify different words. Behind the scenes, it breaks down words into tokens, using a lot of maths and statistics to determine what words are statistically probable to follow your tokens based on what it learnt from it's training data.  


# Inside LLMs
* Parameters --> 
* Layers -->
* Tokens -->
 The more parameter, layers and tokens you feed an LLM, the "smarter" they get.So you'd want to use LLMs with more of these features

## The Reversal Curse 
For LLMs A = B but B != A 
That's what the reversal curse talks about 



# Prompt engineering framework 
* The standard prompt --> A prompt consisting of only a question or instruction

## The set up
* The system message --> A defaut or initial peompt that is provided to the model by it's creator 

* Context --> Look to include additional context it primes the model to think the way you want it to be thinking you want it to
* Managing the token limit of a model is crucial to maintaining the accuracy and cohenrence of the model's outputs 











